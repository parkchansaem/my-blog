{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/TIL/5-16/5-16/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Chan saem 의 블로그"}},"markdownRemark":{"id":"1ee39ee2-c288-5d01-9d9e-be4d0197da41","excerpt":"ML workflow…","html":"<p>ML workflow\n데이터 분석 문제 정의: 이슈 파악&#x26;문제 도출, 분석 데이터 정의, 머신 러닝 문제 정의, 베이스 라인 선정\n데이터 수집 및 정제: 데이터 마트 생성, 데이터 정합성 평가, 데이터 취합, 데이터 포맷 통일\n탐색적 데이터 분석: 결측치 처리, 클래스 불균형 문제, 데이터 시각화, 통계량 분석, 차원의 저주, 상관관계 분석, 피처 추출, 범주형 변수 인코딩\n예측 모델 개발 및 적용: 예측 모델 학습, 모델 성능 개선, 성능 평가, 최종 모델 배포\n데이터 정의-> 데이터 정형화-> EDA->전처리-> ML model-> 평가</p>\n<p>회귀(Regression)</p>\n<ul>\n<li>회귀의 직관적인 의미\n<ul>\n<li>주어진 데이터(X)와 원하는 값(y)사이의 관계를 찾는 방법</li>\n<li>주어진 데이터(X)를 통해서 원하는 값(y=target value)을 예측하는 방법</li>\n</ul>\n</li>\n</ul>\n<p>Linear Regression : 가장 직관적이고 많이 사용되는 선형 회귀 모델</p>\n<p>MSE:평균제곱오차로 선형회귀에서 중심이 되는 자료 오차의 제곱을 평균으로 나눈것으로 0에 가까울수록 추측한 값이 원본에 가까운 것이기 때문에 정확도가 높다고 할수 있고 예측값과 실제값 차이의 면적을 평균이라고 할수 있다.</p>\n<p>Linear regression이 안좋은 예측 결과가 나오면 feature engineering을 통해 새롭게 뽑아서 사용</p>\n<p>LightGBM regressor: 실제 데이터 분석 대회에서 가장 많이 사용하는 효과적인 회귀 모델</p>\n<ul>\n<li>여러 Decision Tree중에 target value를 잘찾는 tree들만 찾아서 그 방향으로 트리를 확장해 나감</li>\n<li>대용량 데이터에 대해서 적은 메모리로도 빠르게 성능이 좋은 회귀 모델을 만들 수 있다.</li>\n<li>Hyper-parameter에 영향을 많이 받기 때문에 parameter tuning이 중요함</li>\n<li>기존에 많이 쓰는 파라미터 세팅을 기억해두고 필요에 따라 다양한 조합을 테스트해봅니다.</li>\n<li>AutoML,pycaret</li>\n</ul>\n<p>Decision tree(CART)->Random forest->Gradient boosting model(GBM)->XGBoost-> Light GBM-> Catboost</p>\n<p>대다수가 같은 모델을 사용하여 보통 feature engining이나 하이퍼 파라미터에서 차이가 남</p>\n<p>회귀 모델 평가</p>\n<ul>\n<li>주어진 데이터로 모델을 학습시키는 것은 지정한 성능 평가 지표를 향상시키는 과정</li>\n<li>성능 평가 지표의 값은 예측 성능을 기준으로 한다.</li>\n<li>정량적 기준을 설정하고, 달성할 때까지 모델을 학습시키고 성능을 개선</li>\n<li>목표한 성능에 도달한 모델을 실제 서비스에 적용</li>\n<li>MSE(Mean Squared Error), RMSLE(Root Mean Squared log error):yi,yihat의 scale 영향을 안받음-outlier에 robust함(영향을 덜 받음) MAE(Mean Absolute Error), R2 Score(Coefficient of Determination)</li>\n</ul>\n<p>비모수적 기법 vs 모수적 기법</p>\n<ul>\n<li>비모수적 기법: 모집단의 확률 분포에 대한 특별한 가정없이, 평균과 분산이라는 지표를 추정하는 것</li>\n<li>모수적 기법: 모집단의 성질에 따라 어떤 확률 분포의 형태인지를 미리 가정한 후, 기대값 혹은 분산을 결정하는 소수의 파라미터를 추정하는 것</li>\n</ul>\n<p>통계 계산 함수</p>\n<ul>\n<li>E(x): 확률변수의 기대값을 계산하는 함수</li>\n<li>V(x): 확률변ㅅ의 분산을 계산하는 함수</li>\n<li>check_prob: 확률변수의 성질을 만족하는 지 검정 후 기대값, 분산을 반환하는 함수</li>\n<li>plot_prob: 확률변수의 확률밀도함수 및 기대값을 시각화하기 위한 함수</li>\n</ul>\n<p>베르누이 분포</p>\n<ul>\n<li>가장 기본적인 이산형 확률 분포</li>\n<li>취할 수 있는 값은 0혹은 1</li>\n<li>1과 0이 나올 확률을 각각 더하면 1이 되어야 하므로, 그 확률을 각각 p와 1-p로 정의</li>\n</ul>\n<p>이항 분포</p>\n<ul>\n<li>성공 확률이 p인 베르누이 시행을 n번 했을 때의 성공 횟수를 나타내는 분포</li>\n<li>파라미터: 성공확률 p, 시행횟수 n</li>\n<li>0&#x3C;p&#x3C;1, n은 1이상인 정수</li>\n</ul>\n<p>기하 분포</p>\n<ul>\n<li>베르누이 시행에서 처음 성공할때까지 반복한 시행횟수에 따른 분포</li>\n</ul>\n<p>푸아송 분포</p>\n<ul>\n<li>임의의 사건이 단위 시간당 발생하는 건수에 따른 확률분포</li>\n<li>파리미터:람다는 양의 실수</li>\n</ul>\n<p>ADSP</p>\n<p>탐색적 자료분석(EDA):데이터가 가지고 있는 특성을 파악하기 위해 시각화하여 분석하는 방식, 시각화하면 이상점을 식별하기 쉽다.\nEDA의 4가지 주제: 저항성의 강조,잔차, 계산, 자료변수의 재표현 그래프를 통한 현시성</p>\n<p>기술 통계: 모집단으로부터 표본을 추출하고 표본이 가지고 있는 정보를 하나의 숫자 또는 그래프의 형태로 표현</p>\n<p>추측 통계: 모집단으로붙 추출된 표본의 표본통계량으로 모집단을 통계적으로 추론</p>\n<p>데이터마이닝 모델링</p>\n<ul>\n<li>대표적인 고급 데이터 분석법이다(ex:시뮬레이션)</li>\n<li>지나치게 통계적 가설이나 유의성에 집착하지마 말고 훈련 및 테스트 성능에 큰 편차가 없고 예상 성능을 만족하면 중단한다. 반드시 다양한 옵션을 주어야 하는 것이 아니다.</li>\n</ul>\n<p>R기초</p>\n<ul>\n<li>벡터 생성 c: c(1,2,3)은 [1,2,3]이고 숫자형 벡터이지만 c(1,2,’a’)처럼 문자형이 원소로 하나라도 껴있으면 문자형 벡터가 됨. c(1:5)는 1부터 5까지라는 뜻:를 ~로 생각</li>\n<li>패키지 설치 및 로드: install.packages(“패키지명”)->library(패키지명)</li>\n<li>행렬을 as.vector함수에 입력하면 열방향으로 1열부터 원소를 나열하는 벡터 생성</li>\n<li>Summary 함수는 4분위수, 최소, 최대, 중앙값, 평균을 출력함</li>\n<li>데이터프레임: 2차원 목록 데이터 구조, 각 열이 다른 데이터 타입을 가질 수 있다. 데이터 테이블이란 데이터 프레임과 유사하지만 보다 월등히 빠른 그루핑과 ordering, 짧은 문장 지원측 면에서 더 매력적</li>\n</ul>\n<p>데이터 마트</p>\n<ul>\n<li>데이터 웨어하우스와 사용자 사이의 중간층에 위치</li>\n<li>CRM관련 업무 중에서 핵심</li>\n</ul>\n<p>요약변수</p>\n<ul>\n<li>수집된 정보를 분석에 맞게 종합한 변수, 재활용성이 높다.</li>\n</ul>\n<p>파생변수</p>\n<ul>\n<li>특정조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여한 변수</li>\n<li>주관적일 수 있어 논리적 타당성을 갖추어야 한다.\nSqldf:R에서 sql명령어를 사용 가능하게 해주는 패키지\nPlyr: apply 함수를 기반으로 가장 필수적인 데이터 처리기능 제공</li>\n</ul>\n<p>결측값(na) 처리 방법</p>\n<ul>\n<li>Completes analysis:결측값이 존재하는 레코드 삭제</li>\n<li>평균 대처법: 결측값을 데이터의 평균으로 대치</li>\n<li>다중 대치법: 대치, 분석, 결합 단계로 진행</li>\n</ul>\n<p>이상값</p>\n<ul>\n<li>잘못 입력한 경우, 의도하지 않게 입력되었고 분석 목적에 맞지 않는 경우</li>\n<li>꼭 제거해야하는 것은 아니므로 적절한 판단 필요</li>\n</ul>\n<p>이상값 인식 방법 3가지</p>\n<ul>\n<li>ESD: 평균으로부터 3 표준편차 떨어진 값</li>\n<li>기하평균 - 2.5 * 표준편차&#x3C; data&#x3C;기하평균+2.5*표준편차를 벗어나는 값</li>\n<li>사분위수 이용하기: Q1-1.5*(IQR)&#x3C;data&#x3C;Q3+1.5*(IQR)을 벗어나는 값, IQR=Q3-Q1, 보통 이러한 범위를 넘어가면 제거하지 않고 범위의 최대 최소값으로 바꾸어 활용</li>\n<li>사기탐지, 의료, 부정사용방지 등등에 쓰일 수 있다.</li>\n</ul>\n<p>통계자료 획득</p>\n<ul>\n<li>전수조사: 전체를 다 조사하는 것 ->시간과 비용이 많이 소요</li>\n<li>표본조사: 일부만 추출하여 모집단을 분석</li>\n</ul>\n<p>표본 추출 방법</p>\n<ul>\n<li>단순랜덤 추출법: 말 그대로 랜덤하게 표본을 뽑음</li>\n<li>계통추출법: 번호를 랜덤하게 부여한 후 특정한 간격별로 추출</li>\n<li>집락추출법: 군집을 나눈 후 군집별로 단순랜덤 추출</li>\n<li>층화추출법: 계층을 고루 대표할 수 있도록 표본 추출</li>\n</ul>\n<p>표본 오차 &#x26; 표본 편의</p>\n<ul>\n<li>표본 오차는 모집단을 대표할 수 있는 표본 단위들이 조사대상으로 추출되지 못함으로서 발생하는 오차</li>\n<li>표본편의는 모수를 작게 또는 크게 할 때 추정하는 것과 같이 표본추출방법에서 기인하는 오차를 의미, 확률화로 최소화하거나 없앨 수 있다.</li>\n</ul>\n<p>척도 구분</p>\n<ul>\n<li>명목척도: 어느 집단에 속하는지 분류</li>\n<li>순서척도: 서열관계가 있을때</li>\n<li>구간척도: 속성의 양을 측정하는 것으로 구간이나 구간 사이의 간격이 의미가 있는 자료, 절대적 원점은 없다.</li>\n<li>비율척도: 절대적 기준인 0이 존재하고 사칙연산이 가능</li>\n</ul>\n<p>확률변수</p>\n<ul>\n<li>이산형: 0이 아닌 확률값을 셀 수 있는 실수값-> 이산형 확률 변수로는 베르누이,이항,기하,다항,푸아송 분포가 있음</li>\n<li>연속형: 확률이 함수형태로 주어져 있다고 생각하면 됨, 균일분포, 정규분포,지수분포,t-분포,카이제곱분포,f-분포가 있음</li>\n</ul>\n<p>추정: 표본으로부터 모수을 추측하는 것</p>\n<ul>\n<li>점추정: 모수가 특정한 값일 것이라고 추정하는 것</li>\n<li>구간측정: 모수가 특정한 구간에 있을 것이라고 선언하는 것, 추정량의 분포에 대한 전제가 주어져야 하고 구해진 구간 안에 모수가 있을 신뢰구간이 주어져야한다.</li>\n</ul>\n<p>가설검정</p>\n<ul>\n<li>귀무가설: 비교하는 값과 차이가 없다를 기본개념으로 하는 가설</li>\n<li>대립가설: 뚜렷한 증거가 있을 때 주장하는 가설</li>\n<li>p값: 귀무가설이 사실일 때, 관측된 검정통계량이 대립가설을 지지하는 방향으로 나올 확률, 우리가 내린 판정이 잘못되었을 실제 확률을 의미</li>\n<li>유의수준: 귀무가설이 옳은데도 이를 기가하는 확률의 크기</li>\n<li>제 1종 오류: 귀무가설이 옳은데 귀무가설을 기가하게 되는 오류</li>\n<li>제 2종 오류: 귀무가설이 틀린데 귀무가설을 채택하는 오류</li>\n</ul>\n<p>비모수적 방법</p>\n<ul>\n<li>자료가 추출된 모집단의 분포에 아무 제약 않고 검정 실시</li>\n<li>분포의 형태에 대해 설정</li>\n<li>절대적인 크기에 의존하지 않는 관측값들의 순위나 두 관측값 차이의 부호 등을 이용</li>\n<li>부호검정, 윌콕슨의 순위합검정, 윌콕슨이 부호순위합검정, 만-위트니의 u검정, 스피어만 순위상관계수</li>\n</ul>\n<p>왜도: 분포의 비대칭 정도를 나타내는 측도(평균 중앙값 최빈값 관계 그림으로 기억)</p>\n<p>상관분석: 데이터 안의 두 변수간의 관계를 알아보기 위한 것</p>\n<ul>\n<li>상관계수의 절대값이 0이면 전혀 상관이 없는 것이고 0.3보다 작으면 거의 상관이 없는 것 절대값이 0.3과 0.7사이라면 약한 상관관계가 있는 것 1과 0.7사이라면 강한 상관이 있는 것</li>\n<li>cor() 혹은 rcorr()함수로 상관계수를 구할 수 있다.</li>\n<li>R로 상관분석을 했을 때, p-value값이 0.05이하인 경우 귀무가설을 기각하고 대립가설을 채택할 수 있다. 즉 변수 간 상관관계가 있다고 볼 수 있다.</li>\n</ul>\n<p>회귀분석: 하나 또는 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정하는 통계법</p>\n<ul>\n<li>P-값이 0.05보다 작으면 추정된 회귀식은 통계적으로 유의수준 5%이하에서 유의미하다고 봄</li>\n<li>결정계수는 R-squared값으로 확인하면 되고 1에 가까울수록 설명력이 높다고 판단할 수 있다. 총 변동 중에서 회귀모형에 의하여 설명되는 변동이 차지하는 비율이다.</li>\n<li>선형회귀분석의 가정\n<ul>\n<li>선형성: 입력변수와 출력변수의 관계가 선형이다.</li>\n<li>등분산성: 오차의 분산이 입력변수와 무관하게 일정하다.</li>\n<li>독립성: 입력변수와 오차는 관련이 없다.</li>\n<li>비상관성: 오차들끼리 상관이 없다.</li>\n<li>정상성: 오차의 분포가 정규분포를 따른다.</li>\n</ul>\n</li>\n<li>데이터의 정규성은 Q-Q plot, Shapiro-walks test, 히스토그램을 사용해 확인 가능</li>\n</ul>\n<p>단계적 변수선택</p>\n<ul>\n<li>전진선택법: 절편만 있는 상수모형으로부터 시작해 중요하다고 생각된ㄴ 변수를 차례대로 추가</li>\n<li>후진제거법: 모든 변수를 포함한 모형에서 출발해 가장 적은 영향을 주는 변수부터 하나씩 제거</li>\n<li>단계선택법: 전진선택법으로 변수를 추가하는데 기존 변수가 영향을 받아 중요도가 약화되면 변수를 다시 제거하는 등 단계별로 추가, 제거 여부를 검토하는 방법</li>\n<li>최적회귀방정식은 모든 후보 모형들에 대해 AIC,BIC를 계산하고 그 값이 최소가 되는 모형 선택</li>\n</ul>\n<p>시계열 자료: 시간의 흐름에 따라 관찰된 값을 뜻함\n정상시계열(일반적으로 분산이 시점에 의존하지 않음을 나타냄)</p>\n<ul>\n<li>모든 시점에 대해 일정한 평균과 분산을 가진다.</li>\n<li>특정한 시차의 길이를 갖는 자기공분산을 측정하더라도 동일한 값을 갖는다.</li>\n</ul>\n<p>비정상시계열을 정상시계열로 전환하는 방법</p>\n<ul>\n<li>평균이 일정하지 않은 경우: 원시계열에 차분(현 시점에서 바로 전 시점의 자료값을 뺌)</li>\n<li>계절성을 갖는 경우: 계절처분 사용</li>\n<li>분산이 일정하지 않은 경우: 자연로그를 취함</li>\n</ul>\n<p>자기회귀 모형(AR)</p>\n<ul>\n<li>시계열 모델 중 자기 자신의 과거 값을 사용하여 설명하는 모형</li>\n<li>백색 잡음의 현재값과 자기 자신의 과거값의 선형 가중합으로 이루어진 정상 확률 모형</li>\n</ul>\n<p>분해시계열: 시계열에 영향을 주는 일반적인 요인을 시계열에서 분리해 분석하는 방법</p>\n<ul>\n<li>경향요인, 계절요인, 순환요인, 불규칙요인으로 이루어짐</li>\n<li>경향은 말 그대로 자료가 오르거나 내리는 추세를 의미</li>\n<li>계절은 고정된 주기에 따라 자료가 변하는 경우</li>\n<li>순환은 경제적이나 자연적인 이유 없이 알려지지 않은 주기를 갖고 변화</li>\n<li>불규칙은 위 3가지로 설명할 수 없을 때</li>\n</ul>\n<p>다차원척도법(MDS)</p>\n<ul>\n<li>객체간 근접성을 시각화하는 통계기법</li>\n<li>개체들을 2차원 또는 3차원 공간상에 점으로 표현하여 개체들 사이의 집단화를 시각적으로 표현하는 분석방법</li>\n<li>계량적MDS-> 비울척도,구간척도 데이터 활용</li>\n<li>비계량적MDS-> 순서척도 데이터 활용</li>\n</ul>\n<p>주성분분석(PCA)</p>\n<ul>\n<li>여러 변수들을 상관관계를 이용해 소수의 주성분으로 차원을 축소하는 것</li>\n<li>Scree plot을 이용하는 경우에는 그래프의 기울기가 완만해져 거의 0에 다다르는 지점에서 주성분의 개수를 구한다.</li>\n<li>대략 85%의 분산설명력을 갖게끔 주성분의 수를 결정한다.</li>\n</ul>\n<p>관측치 수 = 자유도(df)+1</p>\n<p>데이터마이닝</p>\n<ul>\n<li>대용량 데이터에서 의미있는 데이터 패턴을 파악, 예측하여 의사결정에 활용하는 방법</li>\n<li>가설이나 가정없이 다양한 수리 알고리즘을 이용</li>\n<li>데이터 마이닝 도구가 다양하고 체계화되어 환경에 적합한 제품을 선택하여 활용 가능</li>\n<li>알고리즘에 대한 깊은 이해가 없어도 분석에 큰 어려움이 없다.</li>\n<li>분석 결과의 품질을 위해서 풍분한 경험을 가진 전문가가 하면 좋다.\n지도학습:인공신경망, 의사결정나무, 회귀분석, 로지스틱회귀분석, 사례기반추론\n비지도학습: OLAP,연관성 규칙발견, 군집분석, SOM</li>\n</ul>\n<p>데이터마이닝 추진 단계</p>\n<ul>\n<li>목적설정->데이터 준비-> 가공-> 기법적용-> 검증</li>\n</ul>\n<p>데이터 분할</p>\n<ul>\n<li>구축용: 데이터 마이닝 모델을 만드는데 활용하며 보통 50%사용</li>\n<li>검정용: 구축된 모향의 과대추정 또는 과소추정을 미세 조정을 하는데 활용 보통 30%사용</li>\n<li>시험용: 모델의 성능을 검증하는데 활용 보통 20%사용</li>\n<li>홀드아웃 방법: 주어진 데이터를 학습용과 시험용 데이터로 분리하여 사용하는 방법</li>\n<li>교차확인 방법: 주어진 데이터를 K개의 집단으로 구분하여 k-1개의 집단을 학습용으로, 나머지는 검증용으로 설정해 학습하는 방법</li>\n</ul>\n<p>성과분석</p>\n<ul>\n<li>1번은 실제로도 참인데 예측도 참이라고 한 경우</li>\n<li>2번은 실제로는 거짓인데 예측을 참이라고 한 경우</li>\n<li>3번은 실제로 참인데 예측을 거짓이라고 한경우</li>\n<li>4번은 실제로도 거잣인데 예측도 거짓이라고 한경우</li>\n<li>Acuracy=(1+4)/(1+2+3+4) 실제와 맞게 예측한 확률</li>\n<li>특이도(Specificity)=4/(2+4) 실제로 거짓인 사건을 예측도 거짓으로 한 확률이다.</li>\n<li>정확도(Precision)= 1/(1+2) 예측을 참이라고 했는데 실제로도 참일 확률이다.</li>\n<li>재현율(Recall)=민감도(Sensitivity)=1/(1+3) 실제로 참인 경우 중에 예측을 참으로 한 확률</li>\n</ul>\n<p>F1 score = 2*(p*R)/(p+R)\nROC Curve: 가로축을 1- 특이도 세로축을 민감도 값으로 두어 시각화한 그래프, 그래프의 면적이 클수록(1에 가까울수록) 모형의 성능이 좋다고 평가</p>\n<p>분류분석</p>\n<ul>\n<li>데이터가 어떤 그룹에 속하는지 예측하는데 사용되는 기법</li>\n<li>지도학습에 해당</li>\n<li>인공신경망, 의사결정나무, 회귀분석 등등 위에서 다뤘던 지도학습의 대부분이 분류분석에 속함</li>\n<li>향상동 곡선: 분류 분석의 모형평가 방법으로 랜덤 모델과 비교하여 해당 모델의 성과가 얼마나 향상되었는지를 각 등급별로 파악</li>\n</ul>\n<p>로지스틱 회귀분석</p>\n<ul>\n<li>반응변수가 범주형인 경우에 적용되는 회귀분석 모형</li>\n<li>오즈가 함께 증가, 성공할 확률이 실패할 확률의 몇배인지를 나타냄</li>\n</ul>\n<p>의사결정나무</p>\n<ul>\n<li>연속적으로 발생하는 의사결정 문제를 시각화해 의사결정이 이뤄지는 시점과 성과를 한눈에 볼 수 있게 한다. 해석이 간편하다.</li>\n<li>예측력에 치중할 때도 있고 해석력에 치중할 때도 있다.</li>\n<li>대용량 데이터에서도 빠르다.</li>\n<li>비정상 잡음 데이터에 대해서도 민감함이 없다</li>\n<li>상관성이 높은 다른 불필요한 변수가 있어도 크게 영향을 받지 않는다.-> 조건이 맞지 않는 변수는 그냥 버리면 되니 크게 영향을 안받을 것</li>\n<li>새로운 자료에 대한 과대적합이 발생할 수 있다. -> 과대적합: 너무 자세하게 만들어서 다른 자료에 적용할 때 성능이 떨어짐, 과소적합: 모형이 너무 단순해서 성능이 떨어짐</li>\n<li>아래로 내려갈수록 각 마디에서의 불순도는 감소한다.</li>\n</ul>\n<p>형성과정: 성장(분리규칙,정지규칙)-> 가지치기(과대적합되어 현실문제에 적응할 수 있는 적절한 규칙이 나오지 않는 현상 방지)->타당성평가(이익도표,위험도표)-> 해석 및 예측</p>\n<p>불순도 측도: 카이제곱 통계량, 지니지수, 엔트로피 지수</p>\n<p>의사결정나무 알고리즘</p>\n<ul>\n<li>CART:가장 많이 할용되는 알고리즘, 출력변수가 범주형일 경우 지니지수, 연속형일 경우 이진 분리 사용</li>\n<li>C4.5/C5.0: 범주형 입력변수에 대해서는 범주의 수만큼 분리가 일어남, 측도로는 엔트리피지수 사용</li>\n<li>CHAID: 가지치기를 없이 적당한 크기에서 나무 성장을 중지, 입력변수는 반드시 범주형 사용, 측도로는 카이 제곱 통계량 사용</li>\n</ul>\n<p>앙상블 분석: 여러개의 예측 모형들을 만든 후 조합</p>\n<ul>\n<li>배깅: 여러개의 부스트랩 자료를 생성한 후 각 자료에 예측모형을 만든 후 결합, 가지치기를 하지않고 최대로 성장한 의사결정나무 활용</li>\n<li>부스팅: 배깅과 다른 점은 각 자료에 동일한 가중치를 주는 것이 아닌 분류가 잘못된 데이터에 더 큰 가중을 준다.</li>\n<li>랜덤포레스트: 배깅에 랜덤과정을 추가한 방법</li>\n<li>샘플에 한번도 선택되지 않는 원데이터가 발생할 수 있는데 전체 샘플의 36.8%가 해당</li>\n</ul>\n<p>인공신경망</p>\n<ul>\n<li>인간의 뇌를 기반으로 한 추론모델</li>\n<li>역전판 알고리즘을 활용해 비선형성 극복한 모형 등장-> 연결강도를 갱신하기 위해 예측된 결과와 실제값 차이인 error로 가중치 조절</li>\n<li>활성화함수를 사용해 출력을 결정(입력변수의 속성에 따라 선택하는 것은 아님)-> 시그모이드 함수라는 것이 있는데 0~1의 확률값을 갖으며 로지스틱 회귀분석과 유사</li>\n<li>Softmax 함수: 출력 값이 여러개로 주어지고 목표치가 다범주인 경우</li>\n<li>은닉노드의 수는 적절히 큰 값으로 놓고 가중치를 감소시키며 적용하는 것이 좋음-> 은닉층의 뉴런개수는 자동으로 설정되는 것이 아닌 직접 설정해야함. 너무 많이 설정하면 과대적합 너무 적으면 과소적합 일어남(기울기 소실문제)</li>\n</ul>\n<p>군집분석</p>\n<ul>\n<li>군집의 개수나 구조에 대한 가정없이 데이터들 사이의 거리를 기준으로 군집화 유도-> 인공신경망은 개수를 직접 설정해줘야했음</li>\n<li>각 개체의 유사성을 측정하여 분류하고 서로 다른 군집의 객체들과의 상이성을 규명하는 분석방법</li>\n</ul>\n<p>실루엣: 군집분석의 품질을 정량적으로 평가하는 대표적인 지표, 군집 내 데이터간 거리가 짧을수록 군집 간 거리가 멀수로 값이 커짐</p>\n<p>연속형 변수 거리</p>\n<ul>\n<li>유클리디안 거리: 우리가 흔히 아는 좌표계에서의 거리</li>\n<li>표준화 거리: 표준화하게되면 척도, 분산의 차이로 인한 왜곡을 피할 수 있다.</li>\n<li>마할라노비스 거리: 통계적 개념 포함, 변수의 표준화와 상관성을 동시에 고려</li>\n<li>맨하탄거리, 민코우스키 거리</li>\n</ul>\n<p>범주형 변수 거리</p>\n<ul>\n<li>자카드 유사도: Boolean 속성으로 이루어진 두 객체간의 유사도 측정에 사용된다.</li>\n<li>코사인 유사도: 두 단위 벡터의 내적을 이용, 내각의 크기로 유사도를 측정</li>\n</ul>\n<p>계층적 군집 분석</p>\n<ul>\n<li>최단 연결법: 최단거리를 이용해 군집형성, 고립된 군집을 찾는데 중점, 사슬모양의 군집이 생길 수 있음</li>\n<li>최장연결법: 최장거리를 이용해 군집형성, 내부 응집성에 중점을 둠</li>\n<li>중심연결법: 중심간의 거리를 이용해 군집형성</li>\n<li>평균연결법: 계산량이 많지만 모든 데이터를 포함하는 하나의 군집형성</li>\n<li>와드 연결법: 군집내의 오차 제곡합에 기초하여 군집 형성</li>\n</ul>\n<p>비계층적 군집 분석(K 평균 군집분석)</p>\n<ul>\n<li>원하는 군집의 개수와 초기값들을 정해 seed를 중심으로 군집을 형성-> 집단 내 제곱합 그래프를 참고해 군집수를 정할 수 있음(어려움)</li>\n<li>한번 군집이 형성되어도 개체들은 다른 군집으로 이동할 수 있음</li>\n<li>잡음이나 이상값에 영향을 많이 받음</li>\n<li>주어진 목적이 없어 결과 해석이 어렵다.(극복하기 위해 PAM 방법 사용)</li>\n<li>볼록한 형태가 아닌 군집이 존재할 경우 성능이 떨어짐</li>\n<li>내부 구조에 대한 사전정보가 없어도 의미있는 자료구조를 찾을 수 있다는 장점이 있다.</li>\n</ul>\n<p>흔한분포군집: EM알고리즘이 사용된다.</p>\n<p>SOM(자기조직화지도)</p>\n<ul>\n<li>입력변수의 위치 관계를 그대로 보존한다는 특정이 있다.</li>\n<li>역전파 알고리즘을 사용하는 인공신경망과 달리 단 하나의 전방패스를 사용</li>\n<li>연결강도는 입력패턴과 가장 유사한 경쟁층 뉴런이 승자가 된다.</li>\n<li>BMU:SOM에서 선택된 프로토타입 벡터</li>\n<li>입력 변수의 개수와 동일하게 뉴런 수가 존재</li>\n<li>고차원의 데이터를 이해하기 쉬운 저차원의 뉴런으로 정렬</li>\n</ul>\n<p>연관분석</p>","frontmatter":{"title":"5/16","date":"May 16, 2022","description":"공부내역"}},"previous":{"fields":{"slug":"/TIL/5-14/5-14/"},"frontmatter":{"title":"5/14"}},"next":{"fields":{"slug":"/TIL/5-17/5-17/"},"frontmatter":{"title":"5/17"}}},"pageContext":{"id":"1ee39ee2-c288-5d01-9d9e-be4d0197da41","previousPostId":"dda48ca1-2526-5126-8446-158a645516b8","nextPostId":"f84bab12-a786-5ebb-b4bd-ab1957642fba"}},
    "staticQueryHashes": ["2841359383","3257411868"]}